{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03ca1b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go \n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from dateparser import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827e75f1",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "067c75e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Util():\n",
    "    def __init__(self):\n",
    "        self.scaler = None\n",
    "        self.metric_sig_digits = 2\n",
    "    \n",
    "    def get_stock(self, ticker):\n",
    "        ticker_data = yf.Ticker(ticker)\n",
    "        fund_df = ticker_data.history(start=start, end=end)\n",
    "        data = fund_df[['Close']]\n",
    "        data.rename(columns={'Close':ticker}, inplace=True)\n",
    "        return data\n",
    "\n",
    "    def combine_stocks(self, tickers):\n",
    "        data_frames = []\n",
    "        for i in tickers:\n",
    "            data_frames.append(self.get_stock(i))\n",
    "        df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['Date'], how='outer'), data_frames)\n",
    "        return df_merged\n",
    "    \n",
    "    def plot_lines(self, df, label=''):\n",
    "        traces = []\n",
    "        for c in df.columns:\n",
    "            traces.append(go.Scatter(x=df.index, y=df[c].values, name=str(c)+label))\n",
    "        return traces\n",
    "    \n",
    "    def plot_bars(self, df):\n",
    "        traces = []\n",
    "        df.sort_values(df.columns[0], inplace=True)\n",
    "        for c in df.columns:\n",
    "            traces.append(go.Bar(x=df.index, y=df[c].values, name=c))\n",
    "        return traces\n",
    "\n",
    "    def plot_comparison(self, actual, predicted_baseline, predicted_best, trials=[], stock=''):\n",
    "        plt.plot(actual, color='black',label='Actual')\n",
    "        plt.plot(predicted_best, color='green',label='Best Model')\n",
    "        plt.plot(predicted_baseline, color='blue',label='Base Model')\n",
    "        plt.title('Best vs Baseline model')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel(stock+' Stock Price')\n",
    "        if len(trials)>0:\n",
    "            for i,pred in enumerate(trials):\n",
    "                plt.plot(pred,label='Trial:'+str(i))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def calculate_metric(self, metricname, true, pred):\n",
    "        if metricname=='rmse':\n",
    "            metric = math.sqrt(mean_squared_error(true, pred))\n",
    "        if metricname=='mse':\n",
    "            metric = mean_squared_error(true, pred)\n",
    "        if metricname=='mae':\n",
    "            metric = mean_absolute_error(true, pred)\n",
    "        if metricname=='mape':\n",
    "            metric = mean_absolute_percentage_error(true, pred)\n",
    "        if metricname=='r2':\n",
    "            metric = r2_score(true, pred)\n",
    "        return round(metric, self.metric_sig_digits)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa1a486",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4c21c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modeling():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.util = Util()\n",
    "        self.model_objects = []\n",
    "        self.g_epochs = 5\n",
    "        self.g_batch_size = 10\n",
    "        \n",
    "    def transform(self, transform, train, val, inputs, target):\n",
    "        if type(transform)!=str:\n",
    "            self.util.xscaler = transform\n",
    "            self.util.yscaler = transform\n",
    "            train_scaled = pd.DataFrame(self.util.xscaler.fit_transform(train), columns=train.columns, index=train.index)\n",
    "            val_scaled = pd.DataFrame(self.util.xscaler.fit_transform(val), columns=val.columns, index=val.index)\n",
    "            self.util.yscaler.fit_transform(train[target].values.reshape(-1,1))\n",
    "        else:\n",
    "            self.util.xscaler = transform\n",
    "            self.util.yscaler = transform\n",
    "            if transform=='diff1':\n",
    "                train_ = train.diff().backfill()\n",
    "                val_ = val.diff().backfill()\n",
    "            elif transform=='log':\n",
    "                train_ = np.log(train)\n",
    "                val_ = np.log(val.diff())\n",
    "            train_scaled = pd.DataFrame(train_, columns=train.columns, index=train.index)\n",
    "            val_scaled = pd.DataFrame(val_, columns=val.columns, index=val.index)\n",
    "        self.train = train_scaled\n",
    "        self.val = val_scaled\n",
    "        self.y_train = train_scaled[[target]]\n",
    "        self.y_val = val_scaled[[target]]\n",
    "        self.x_train = None\n",
    "        self.x_val = None\n",
    "        if inputs is not None:\n",
    "            self.x_train = train_scaled[inputs]\n",
    "            self.x_val = val_scaled[inputs]\n",
    "        \n",
    "\n",
    "        \n",
    "    def data_preprocessing(self, data, split, target, inputs, transformer=StandardScaler()):\n",
    "        split_date = parse(split,settings={'PREFER_DAY_OF_MONTH': 'first', 'PREFER_DATES_FROM': 'past'})\n",
    "        train = data[:split_date].iloc[:,:]\n",
    "        val = data[split_date:].iloc[:,:]\n",
    "        self.transform(transformer, train, val, inputs, target)\n",
    "        print(\"Total data:\"+str(data.shape))\n",
    "        print(\"Train data:\"+str(train.shape))\n",
    "        print(\"Val data:\"+str(val.shape))\n",
    "\n",
    "    \n",
    "    def preprocessed_check(self):\n",
    "        print(self.train.columns, self.val.columns)\n",
    "        train_traces = self.util.plot_lines(self.train)\n",
    "        val_traces = self.util.plot_lines(self.val)\n",
    "        iplot(train_traces+val_traces)\n",
    "    \n",
    "    def corr_check(self):\n",
    "        corr = self.x_train.corr()\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "        cax = ax.matshow(corr, cmap='coolwarm')\n",
    "        for i in range(corr.shape[0]):\n",
    "            for j in range(corr.shape[1]):\n",
    "                text = ax.text(j, i, f\"{corr.iloc[i, j]:.2f}\", ha='center', va='center', color='black')\n",
    "\n",
    "        ax.set_xticklabels(corr.columns)\n",
    "        ax.set_yticklabels(corr.index)\n",
    "        plt.show()\n",
    "        \n",
    "    def run_optuna(self, models, hyperparams, metric, optuna_trials=20):\n",
    "        self.hyperparams = hyperparams\n",
    "        self.studies = []\n",
    "        self.best_params = {}\n",
    "        self.best_scores = {}\n",
    "        def optuna_objective(trial):\n",
    "            current_model = study.user_attrs[\"current_model\"]\n",
    "            params = copy.deepcopy(self.hyperparams[current_model])\n",
    "            for p in params:\n",
    "                if p in ['positive', 'fit_intercept', 'optimizer']:\n",
    "                    params[p] = trial.suggest_categorical(p,params[p])\n",
    "                elif p in ['alpha', 'learning_rate']:\n",
    "                    params[p] = trial.suggest_uniform(p,params[p][0],params[p][1])\n",
    "                elif p in ['units']:\n",
    "                    params[p] = trial.suggest_int(p,params[p][0],params[p][1])\n",
    "            regressor = self.get_model(current_model, params)\n",
    "            score = self.train_and_evaluate_optimize(regressor, metric)\n",
    "            return score\n",
    "        start = time.time()\n",
    "        for model in models:\n",
    "            name=type(model).__name__\n",
    "            if name in self.hyperparams:\n",
    "                study = optuna.create_study(storage=\"sqlite:///\"+db_name, \n",
    "                        study_name=\"Optimize-Experiment-\"+name,\n",
    "                        direction=\"minimize\", \n",
    "                        sampler=optuna.samplers.TPESampler(),\n",
    "                        pruner=optuna.pruners.MedianPruner(\n",
    "                            n_startup_trials=2, n_warmup_steps=optuna_trials/2\n",
    "                        )\n",
    "                       )\n",
    "                study.set_user_attr(\"current_model\", name)\n",
    "                start = time.time()\n",
    "                study.optimize(optuna_objective, n_trials=optuna_trials)\n",
    "                self.studies.append(study)\n",
    "                self.best_params[name] = study.best_params\n",
    "                self.best_scores[name] = self.train_and_evaluate(self.get_model(name, study.best_params))\n",
    "                print(model, \"Best parameters: \",study.best_params)\n",
    "                time_taken = time.time() - start\n",
    "                print(f\"Optimization for Model-{name} completed in {time_taken} seconds.\")\n",
    "            else:\n",
    "                print(name, 'non-optuna')\n",
    "                self.best_scores[name] = self.train_and_evaluate(self.get_model(name,{}))\n",
    "        time_taken = time.time() - start\n",
    "        print(f\"Total Optimization completed in {time_taken} seconds.\")\n",
    "            \n",
    "    \n",
    "    def train_and_evaluate_optimize(self,model, metric):\n",
    "        if 'type' not in str(type(model)):\n",
    "            model.fit(self.x_train, self.y_train)\n",
    "            prediction = self.get_predictions(model)\n",
    "        else:\n",
    "            model = model(self.y_train, order=(1,0,0), exog=self.x_train)\n",
    "            model_fit = model.fit()\n",
    "            prediction = self.get_predictions(model_fit)\n",
    "        metric_ = self.util.calculate_metric(metric, self.y_val, prediction)\n",
    "        return metric_\n",
    "    \n",
    "    def get_model(self, model_name, params):\n",
    "        if model_name=='LinearRegression':\n",
    "            return self.linear_reg(params)\n",
    "        elif model_name=='Ridge':\n",
    "            return self.ridge(params)\n",
    "        elif model_name=='Lasso':\n",
    "            return self.lasso(params)\n",
    "        elif model_name=='DecisionTreeRegressor':\n",
    "            return self.dt(params)\n",
    "        elif model_name=='Sequential':\n",
    "            return self.lstm(params)\n",
    "        else:\n",
    "            return self.linear_reg({})\n",
    "        \n",
    "    \n",
    "    \n",
    "    def lstm_model(self,params, x_shape):\n",
    "        regressor = Sequential()\n",
    "        # First LSTM layer with Dropout regularisation\n",
    "        regressor.add(LSTM(units=params['n_unit'], return_sequences=True, input_shape=(x_shape,1)))\n",
    "        regressor.add(Dropout(0.2))\n",
    "        # Second LSTM layer\n",
    "        regressor.add(LSTM(units=params['n_unit'], return_sequences=True))\n",
    "        regressor.add(Dropout(0.2))\n",
    "        # Third LSTM layer\n",
    "        regressor.add(LSTM(units=params['n_unit'], return_sequences=True))\n",
    "        regressor.add(Dropout(0.2))\n",
    "        # Fourth LSTM layer\n",
    "        regressor.add(LSTM(units=params['n_unit']))\n",
    "        regressor.add(Dropout(0.2))  \n",
    "        # The output layer\n",
    "        regressor.add(Dense(units=1))\n",
    "        # Compiling the RNN\n",
    "        regressor.compile(optimizer=params['optimizer'], loss='mean_squared_error')\n",
    "        return regressor\n",
    "    \n",
    "    # Build models\n",
    "    def linear_reg(self, params=None):\n",
    "        regressor = LinearRegression(**params)\n",
    "        return regressor\n",
    "    def ridge(self, params=None):\n",
    "        regressor = Ridge(**params)\n",
    "        return regressor\n",
    "    def lasso(self, params=None):\n",
    "        regressor = Lasso(**params)\n",
    "        return regressor\n",
    "    def dt(self, params=None):\n",
    "        regressor = DecisionTreeRegressor(**params)\n",
    "        return regressor\n",
    "    def rf(self, params=None):\n",
    "        regressor = RandomForestRegressor(**params)\n",
    "        return regressor\n",
    "    def lg(self, params=None):\n",
    "        regressor = LGBMRegressor(**params)\n",
    "        return regressor\n",
    "    def xg(self, params=None):\n",
    "        regressor = XGBRegressor(**params)\n",
    "        return regressor\n",
    "    def arima(self, params=None):\n",
    "        regressor = ARIMA\n",
    "        self.arimaparams = params\n",
    "        return regressor\n",
    "    def lstm(self, params=None):\n",
    "        #data reshape\n",
    "#         temp_x_train = np.reshape(self.x_train.values, (self.x_train.shape[0], 1, self.x_train.shape[1]))\n",
    "        regressor = Sequential()\n",
    "        regressor.add(LSTM(units=params['units'], input_shape=(self.x_train.shape[1],1)))\n",
    "        regressor.add(Dense(1))\n",
    "        regressor.compile(optimizer=params['optimizer'], loss='mse')\n",
    "        return regressor\n",
    "    \n",
    "    def get_predictions(self, model):\n",
    "        if 'Results' in str(type(model)):\n",
    "            if not self.x_val.empty:\n",
    "                raw_prediction = np.array(model.forecast(steps=self.y_val.shape[0], exog=self.x_val))\n",
    "            else:\n",
    "                raw_prediction = np.array(model.forecast(steps=self.y_val.shape[0]))\n",
    "        else:\n",
    "            raw_prediction = model.predict(self.x_val)\n",
    "        if type(self.util.yscaler)!=str:\n",
    "            prediction = pd.DataFrame(self.util.yscaler.inverse_transform(raw_prediction.reshape(-1,1)), columns = self.y_train.columns, index=self.y_val.index)\n",
    "        else:\n",
    "            if self.util.yscaler=='diff1':\n",
    "                prediction = pd.DataFrame(raw_prediction.cumsum(), columns = self.y_train.columns, index=self.y_val.index)\n",
    "            elif self.util.yscaler=='log':\n",
    "                prediction = pd.DataFrame(np.exp(raw_prediction), columns = self.y_train.columns, index=self.y_val.index)\n",
    "        return prediction\n",
    "    \n",
    "    def train_and_evaluate(self,model):\n",
    "        metrics={}\n",
    "        if 'type' not in str(type(model)):\n",
    "            if type(model)!=Sequential:\n",
    "                model.fit(self.x_train, self.y_train)\n",
    "            else:\n",
    "                model.fit(self.x_train, self.y_train, epochs = self.g_epochs, batch_size=self.g_batch_size)\n",
    "            prediction = self.get_predictions(model)\n",
    "            self.model_objects.append(model)\n",
    "        else:\n",
    "            if self.arimaparams:\n",
    "                order = self.arimaparams['order'] if 'order' in self.arimaparams else (1,0,0)\n",
    "            if self.x_train.empty:\n",
    "                model = model(self.y_train, order=order, exog=self.x_train)\n",
    "            else:\n",
    "                model = model(self.y_train, order=order)\n",
    "            model_fit = model.fit()\n",
    "            print(model_fit.summary(),'\\n\\n\\n')\n",
    "            prediction = self.get_predictions(model_fit)\n",
    "            self.model_objects.append(model_fit)\n",
    "        metric_list = ['rmse','mse','mae','mape','r2']\n",
    "        for m in metric_list:\n",
    "            metrics[m] = self.util.calculate_metric(m, self.y_val, prediction)\n",
    "        return metrics\n",
    "    \n",
    "    def run_models(self, models):\n",
    "        self.scores = {}\n",
    "        for model in models:\n",
    "            model_name = type(model).__name__\n",
    "            metrics = self.train_and_evaluate(model)\n",
    "            self.scores[model_name] = metrics\n",
    "            \n",
    "    def objective(self,trial):\n",
    "        lstm_params = {\n",
    "                  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "                  'optimizer': trial.suggest_categorical(\"optimizer\", [\"rmsprop\",\"adam\",\"sgd\",\"adagrad\",\"adadelta\"]),\n",
    "                  'units': trial.suggest_int(\"units\", 20, 40)\n",
    "                  }\n",
    "        regressor = self.build_lstm_model(lstm_params, x.shape[1])\n",
    "        score = self.train_and_evaluate(regressor, epochs, batch_size)\n",
    "        return score\n",
    "            \n",
    "    def plot_predictions(self, num):\n",
    "        model_object = self.model_objects[num]\n",
    "        mname = str(model_object).split('(')[0]\n",
    "        prediction = self.get_predictions(model_object)\n",
    "        pred = self.util.plot_lines(prediction, '_prediction_'+mname)\n",
    "        if type(self.util.yscaler)!=str:\n",
    "            y_true = pd.DataFrame(self.util.yscaler.inverse_transform(self.y_val), index=self.y_val.index, columns=self.y_val.columns)\n",
    "        else:\n",
    "            if self.util.yscaler=='diff1':\n",
    "                y_true = pd.DataFrame(self.y_val.cumsum(), columns = self.y_train.columns, index=self.y_val.index)\n",
    "            elif self.util.yscaler=='log':\n",
    "                y_true = pd.DataFrame(np.exp(self.y_val), columns = self.y_train.columns, index=self.y_val.index)\n",
    "        true = self.util.plot_lines(y_true)\n",
    "        iplot(pred+true)\n",
    "            \n",
    "            \n",
    "    def plot_metrics(self, best_models=False, baseline=False):\n",
    "        metric_frame = pd.DataFrame(self.scores).T if not best_models else pd.DataFrame(self.best_scores).T\n",
    "        og_metrics = pd.DataFrame(self.scores).T if baseline else None\n",
    "        og_traces = []\n",
    "        for metric in metric_frame.columns:\n",
    "            traces = self.util.plot_bars(metric_frame[[metric]].T)\n",
    "            if baseline:\n",
    "                og_traces = self.util.plot_bars(og_metrics[[metric]].T)\n",
    "        iplot(traces+og_traces)\n",
    "            \n",
    "    def print_metrics(self):\n",
    "        for k in self.scores:\n",
    "            print('\\n'+str(k))\n",
    "            for m,v in self.scores[k].items():\n",
    "                print(m +\" : \"+str(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f7a43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
